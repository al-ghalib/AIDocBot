# ğŸ©º AI DocBot â€“ Vision & Voice Powered Healthcare Assistant

**AI DocBot** is a voice-interactive virtual healthcare assistant powered by **LLMs, computer vision**, and **text-to-speech**. Patients can upload an image and speak about their symptoms, and the AI responds like a real doctor â€” with visual analysis, diagnosis, and vocal guidance.

> âš ï¸ *For educational purposes only â€“ Not a replacement for real medical advice.*

---

## ğŸš€ Features

- ğŸ¤ **Speech-to-Text** with Whisper (`groq`)
- ğŸ§  **Medical Image Analysis** using `llama-3.2-11b-vision-preview`
- ğŸ—£ï¸ **Text-to-Speech** with [ElevenLabs](https://www.elevenlabs.io) or [gTTS](https://pypi.org/project/gTTS/)
- ğŸ“· Upload any image of a skin problem, wound, or visible condition
- ğŸ§¾ Realistic medical advice in conversational tone
- ğŸ¤– Clean, interactive UI with [Gradio](https://gradio.app/)

---

## ğŸ§ª Demo

![Demo UI](./screenshots/ui.png) <!-- optional screenshot -->

---

## ğŸ› ï¸ Tech Stack

| Tech              | Purpose                                |
|-------------------|----------------------------------------|
| Python            | Core language                          |
| Gradio            | UI framework                           |
| Groq              | LLMs + Whisper API                     |
| ElevenLabs / gTTS | Text-to-speech voices                  |
| Pydub / FFMPEG    | Audio conversion and processing        |
| Dotenv            | Secret management                      |

---

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```sh
git clone https://github.com/al-ghalib/AIDocBot.git
cd AIDocBot
```

### 2ï¸âƒ£ Create a virtual environment (Optional but recommended)

```sh
python -m venv venv  # Windows: python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set up API keys

Create a `.env` file in the project root and add your **Google API Key and Groq API Key**:

```
GROQ_API_KEY=your_groq_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
```


## ğŸš¦ Run Locally

```bash
python app.py
```

Visit [http://localhost:7860](http://localhost:7860)

---

## ğŸ§  Future Improvements

- ğŸ¤– Use state-of-the art LLMs, especially for vision (Paid LLMs)
- ğŸ§¯ Fine-tune vision model on Medical Images
- ğŸ©º Store patient data with session tracking
- ğŸ—‚ï¸ Add multi-image comparison
- ğŸŒ Add multilingual capabilities
- ğŸ§¬ Connect with actual health APIs (e.g. symptom checkers)
- ğŸ’¬ Chat history with memory and summary

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change or improve.

---

## ğŸ“„ License

MIT License â€“ use freely with credit.

---

## ğŸ‘¨â€âš•ï¸ Disclaimer

This application is intended for **learning and research** only. It does **not** provide real medical advice. For actual medical concerns, consult a licensed healthcare professional.

---

### Made with â¤ï¸ by [Abdullah Al Ghalib](https://www.linkedin.com/in/abdullah-al-ghalib)

